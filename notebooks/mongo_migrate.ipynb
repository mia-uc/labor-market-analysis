{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN9modRJeqUD",
        "outputId": "0ef9db9f-1c80-4eec-d986-5a52de18c65f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'labor-market-analysis': No such file or directory\n",
            "Cloning into 'labor-market-analysis'...\n",
            "remote: Enumerating objects: 194, done.\u001b[K\n",
            "remote: Counting objects: 100% (194/194), done.\u001b[K\n",
            "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "remote: Total 194 (delta 96), reused 151 (delta 60), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (194/194), 55.41 KiB | 2.22 MiB/s, done.\n",
            "Resolving deltas: 100% (96/96), done.\n",
            "/content/labor-market-analysis\n"
          ]
        }
      ],
      "source": [
        "!rm -r labor-market-analysis\n",
        "!git clone https://github.com/mia-uc/labor-market-analysis.git\n",
        "%cd labor-market-analysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBBje0HMe4jn",
        "outputId": "90663e43-8ba0-4ac2-8a42-91a8bca9b345"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting beautifulsoup4==4.12.2\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2022.12.7)\n",
            "Collecting charset-normalizer==3.1.0\n",
            "  Downloading charset_normalizer-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click==8.1.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (8.1.3)\n",
            "Collecting colorama==0.4.6\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting commonmark==0.9.1\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython==2.3.0\n",
            "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna==3.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (3.4)\n",
            "Collecting Pygments==2.15.1\n",
            "  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymongo==4.3.3\n",
            "  Downloading pymongo-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv==1.0.0\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting requests==2.28.2\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich==12.6.0\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shellingham==1.5.0.post1\n",
            "  Downloading shellingham-1.5.0.post1-py2.py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: soupsieve==2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.4.1)\n",
            "Requirement already satisfied: typer==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.7.0)\n",
            "Requirement already satisfied: urllib3==1.26.15 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (1.26.15)\n",
            "Installing collected packages: commonmark, shellingham, python-dotenv, Pygments, dnspython, colorama, charset-normalizer, beautifulsoup4, rich, requests, pymongo\n",
            "  Attempting uninstall: Pygments\n",
            "    Found existing installation: Pygments 2.14.0\n",
            "    Uninstalling Pygments-2.14.0:\n",
            "      Successfully uninstalled Pygments-2.14.0\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 2.0.12\n",
            "    Uninstalling charset-normalizer-2.0.12:\n",
            "      Successfully uninstalled charset-normalizer-2.0.12\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.11.2\n",
            "    Uninstalling beautifulsoup4-4.11.2:\n",
            "      Successfully uninstalled beautifulsoup4-4.11.2\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.3.4\n",
            "    Uninstalling rich-13.3.4:\n",
            "      Successfully uninstalled rich-13.3.4\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pygments-2.15.1 beautifulsoup4-4.12.2 charset-normalizer-3.1.0 colorama-0.4.6 commonmark-0.9.1 dnspython-2.3.0 pymongo-4.3.3 python-dotenv-1.0.0 requests-2.28.2 rich-12.6.0 shellingham-1.5.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GetOnBoard-Cookie'] ='_fbp=fb.1.1681949485147.1531023751; _ga_QT8F9LD9HL=GS1.1.1682476726.10.1.1682476737.0.0.0; _rdt_uuid=1681949567752.d94153d9-04b7-4b37-9355-44db561e63fe; _ga=GA1.1.2068924471.1681949022; _getonboard_session=8c808266dccd3f30da6fcbc6b4f65275; _gat_UA-23995740-1=1; _gat_UA-23995740-1UA-23995740-1=1; _gid=GA1.2.791463878.1682386064; _gat=1; cookies_privacy_policy_consent=true; lang=en; chaskiq_ap_session_ZbJiDh782OenBxQjxdhytQ=eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9LWlcxaGFXeEpJaWhrWVc1cFpXeHZjbXhoYm1SdmIzSjBhWHB3WVdOb1pXTnZRR2R0WVdsc0xtTnZiUVk2QmtWVU9nbDBlWEJsTUE9PSIsImV4cCI6bnVsbCwicHVyIjoibG9naW4ifX0=--9215472afd83702497b4b7e35d711e5fe30f7578f169ba86b49af928401f8b0e; _gcl_au=1.1.1265533573.1681949447'\n",
        "os.environ['GetOnBoard-X-CLIENT-ID']='b8bc579d-6c09-4b07-a55b-0bd0bdb9d7cf-1682476724396'\n",
        "os.environ['GetOnBoard-X-CSRF-Token']='wWGAUiNNS1Fst47dA5v4AHXhRLwbVtSNhmVwgiNqiR1It3o6MfFkmdshck5HuhEgxN4KSkVNw0gpcenaVLYgiw=='\n",
        "os.environ['GetOnBoard-X-NewRelic-ID']='VQYDU15WCBAGU1ZXBAMD'\n",
        "\n",
        "os.environ['MONGO_CONN_STRING']='mongodb://mongodb.natasquad.com:27033'\n",
        "os.environ['MONGO_DB']='jobs'\n",
        "\n",
        "os.environ['Laborum-Cookie']='_fbp=fb.1.1682096008262.1361568721; _ga=GA1.2.945804969.1682096004; _ga_PDJ8VBBGDL=GS1.1.1682096004.1.1.1682096026.0.0.0; _gid=GA1.2.885773853.1682096006; _gs=2.s(); _gu=399a1caa-f288-4037-aa9b-33f2679a8698; _gw=2.u%5B%2C%2C%2C%2C%5Dv%5B~govw5%2C~1%2C~0%5Da(); _hjAbsoluteSessionInProgress=0; _hjFirstSeen=1; _hjIncludedInSessionSample_40018=0; _hjSessionUser_40018=eyJpZCI6IjZmOGRlZjU3LTM1YzktNWY0OS05YzI1LTQ4MzMxYWUxMDQ4NCIsImNyZWF0ZWQiOjE2ODIwOTYwMTMwMzQsImV4aXN0aW5nIjpmYWxzZX0=; _hjSession_40018=eyJpZCI6ImE0MDUzZjdhLWNhZTMtNGIzMi04MDAxLWRkMjYzNGUzYTQzMSIsImNyZWF0ZWQiOjE2ODIwOTYwMTMwNDUsImluU2FtcGxlIjpmYWxzZX0=; ln_or=eyI1MzA0MDAxIjoiZCJ9; _dc_gtm_UA-167099-53=1;'\n",
        "os.environ['Laborum-Session']='eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzZXNzaW9uSWQiOiJmYTVkYjRmMC1lMDY0LTExZWQtODc0NS0xOWNhODQ2ZmJiZjYiLCJpYXQiOjE2ODIwOTU5ODIsImV4cCI6MTY4NDY4Nzk4Mn0.cKwIL-rZlfi7j8vAkOw7yuJRUhVyYu84BRrfQzqxRJA'\n",
        "\n",
        "os.environ['TrabajandoCL-Cookie']='_ga_75E5MQL3SR=GS1.1.1682095986.1.1.1682096614.0.0.0; _ga=GA1.2.1940944839.1682095987; _gid=GA1.2.898047264.1682095994; _gat_UA-5352676-2=1'\n",
        "\n",
        "\n",
        "os.environ['DESTINO_MONGO_CONN_STRING']='mongodb+srv://DataScienceTeam:rNA6xe4OU7cvv8it@jobsdatalake.goyvrjl.mongodb.net/?retryWrites=true&w=majority'\n"
      ],
      "metadata": {
        "id": "DnX2jAvAfdGV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient"
      ],
      "metadata": {
        "id": "jRtLBrvEf4ML"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "connection_string =  os.getenv(\"MONGO_CONN_STRING\")\n",
        "db_name = os.getenv('MONGO_DB')\n",
        "\n",
        "# Conexión con la instancia de Origen\n",
        "origen_cliente = MongoClient(connection_string)\n",
        "origen_db = origen_cliente[db_name]\n",
        "des_connection_string =  os.getenv(\"DESTINO_MONGO_CONN_STRING\")\n",
        "\n",
        "# Conexión con la instancia de Destino\n",
        "destino_cliente = MongoClient(des_connection_string)\n",
        "destino_db = destino_cliente[db_name]\n",
        "\n",
        "for collection in ['Laborum']:\n",
        "    print(f'------------------- {collection} --------------------------')\n",
        "    origen_collection = origen_db[collection]\n",
        "    destino_collection = destino_db[collection]\n",
        "\n",
        "    # Copiar los datos de la colección desde origen a destino\n",
        "    for i, documento in enumerate(origen_collection.find()):\n",
        "        print(f'------------------- {i} --------------------------', end='\\r')\n",
        "        destino_collection.insert_one(documento)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHiEgqxaf5tb",
        "outputId": "e8dc0760-f825-4ab8-f382-dc4a5a2f6cfb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------- Laborum --------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_XJ3A8Oen0cr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}